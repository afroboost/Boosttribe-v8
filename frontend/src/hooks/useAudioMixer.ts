import { useState, useCallback, useRef, useEffect } from 'react';

/**
 * üéß AUDIO MIXER HOOK - Boosttribe v8
 * 
 * Cr√©e un mixeur avec des canaux ind√©pendants pour :
 * - Musique (HTML5 Audio)
 * - Micro H√¥te (WebRTC)
 * - Volume Tribu (Participants entrants)
 * - Volume Voix H√¥te (Pour participants)
 */

export interface MixerState {
  musicVolume: number;      // 0-1 - Volume musique
  micVolume: number;        // 0-1 - Volume micro h√¥te
  tribeVolume: number;      // 0-1 - Volume participants (pour l'h√¥te)
  hostVoiceVolume: number;  // 0-1 - Volume voix h√¥te (pour participants)
  isInitialized: boolean;
}

export interface UseAudioMixerOptions {
  onInitialized?: () => void;
}

export interface UseAudioMixerReturn {
  state: MixerState;
  initialize: () => boolean;
  setMusicVolume: (volume: number) => void;
  setMicVolume: (volume: number) => void;
  setTribeVolume: (volume: number) => void;
  setHostVoiceVolume: (volume: number) => void;
  connectMusicSource: (audioElement: HTMLAudioElement) => void;
  connectMicSource: (stream: MediaStream) => MediaStream;
  connectHostVoice: (audioElement: HTMLAudioElement) => void;
  disconnectMusic: () => void;
  disconnectMic: () => void;
  getContext: () => AudioContext | null;
}

const initialState: MixerState = {
  musicVolume: 0.8,
  micVolume: 1.0,
  tribeVolume: 1.0,
  hostVoiceVolume: 1.0,
  isInitialized: false,
};

/**
 * Hook pour g√©rer le mixage audio avec des canaux ind√©pendants
 * La musique et le micro ne s'affectent PAS mutuellement
 */
export function useAudioMixer(options: UseAudioMixerOptions = {}): UseAudioMixerReturn {
  const { onInitialized } = options;
  
  const [state, setState] = useState<MixerState>(initialState);
  
  // Refs pour l'AudioContext et les n≈ìuds
  const audioContextRef = useRef<AudioContext | null>(null);
  
  // GainNodes s√©par√©s
  const musicGainRef = useRef<GainNode | null>(null);
  const micGainRef = useRef<GainNode | null>(null);
  const tribeGainRef = useRef<GainNode | null>(null);
  const hostVoiceGainRef = useRef<GainNode | null>(null);
  
  // Source nodes
  const musicSourceRef = useRef<MediaElementAudioSourceNode | null>(null);
  const micSourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const hostVoiceSourceRef = useRef<MediaElementAudioSourceNode | null>(null);
  
  // Track connected elements
  const connectedMusicElement = useRef<HTMLAudioElement | null>(null);
  const connectedHostVoiceElement = useRef<HTMLAudioElement | null>(null);

  /**
   * Initialise l'AudioContext et les GainNodes
   */
  const initialize = useCallback((): boolean => {
    if (audioContextRef.current) {
      return true; // D√©j√† initialis√©
    }
    
    try {
      // Cr√©er l'AudioContext
      const AudioContextClass = window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext;
      const ctx = new AudioContextClass();
      audioContextRef.current = ctx;
      
      // Cr√©er les GainNodes ind√©pendants
      // üéµ Canal A: Musique
      musicGainRef.current = ctx.createGain();
      musicGainRef.current.gain.value = state.musicVolume;
      musicGainRef.current.connect(ctx.destination);
      
      // üé§ Canal B: Micro H√¥te
      micGainRef.current = ctx.createGain();
      micGainRef.current.gain.value = state.micVolume;
      micGainRef.current.connect(ctx.destination);
      
      // üë• Canal C: Volume Tribu (participants entrants)
      tribeGainRef.current = ctx.createGain();
      tribeGainRef.current.gain.value = state.tribeVolume;
      tribeGainRef.current.connect(ctx.destination);
      
      // üîä Canal D: Voix H√¥te (pour participants)
      hostVoiceGainRef.current = ctx.createGain();
      hostVoiceGainRef.current.gain.value = state.hostVoiceVolume;
      hostVoiceGainRef.current.connect(ctx.destination);
      
      console.log('üéß [AUDIO] Mixer initialized - Independent channels active');
      console.log('üéß [AUDIO] - Music channel: GainNode A');
      console.log('üéß [AUDIO] - Mic channel: GainNode B');
      console.log('üéß [AUDIO] - Tribe channel: GainNode C');
      console.log('üéß [AUDIO] - Host voice channel: GainNode D');
      
      setState(prev => ({ ...prev, isInitialized: true }));
      onInitialized?.();
      
      return true;
    } catch (err) {
      console.error('üéß [AUDIO] Failed to initialize mixer:', err);
      return false;
    }
  }, [state.musicVolume, state.micVolume, state.tribeVolume, state.hostVoiceVolume, onInitialized]);

  /**
   * Connecte un √©l√©ment audio HTML5 au canal musique
   */
  const connectMusicSource = useCallback((audioElement: HTMLAudioElement) => {
    const ctx = audioContextRef.current;
    if (!ctx || !musicGainRef.current) {
      console.warn('üéß [AUDIO] Mixer not initialized, initializing now...');
      initialize();
      // Retry after init
      setTimeout(() => connectMusicSource(audioElement), 100);
      return;
    }
    
    // √âviter de reconnecter le m√™me √©l√©ment
    if (connectedMusicElement.current === audioElement && musicSourceRef.current) {
      return;
    }
    
    // D√©connecter l'ancienne source
    if (musicSourceRef.current) {
      try {
        musicSourceRef.current.disconnect();
      } catch (e) {
        // Ignore disconnect errors
      }
    }
    
    try {
      // Cr√©er la source √† partir de l'√©l√©ment audio
      const source = ctx.createMediaElementSource(audioElement);
      source.connect(musicGainRef.current);
      
      musicSourceRef.current = source;
      connectedMusicElement.current = audioElement;
      
      console.log('üéß [AUDIO] Music source connected to GainNode A');
    } catch (err) {
      // L'√©l√©ment est peut-√™tre d√©j√† connect√©
      console.warn('üéß [AUDIO] Music source already connected or error:', err);
    }
  }, [initialize]);

  /**
   * Connecte un stream micro au canal micro
   * Retourne un nouveau stream avec le gain appliqu√© (pour WebRTC)
   */
  const connectMicSource = useCallback((stream: MediaStream): MediaStream => {
    const ctx = audioContextRef.current;
    if (!ctx || !micGainRef.current) {
      console.warn('üéß [AUDIO] Mixer not initialized for mic');
      initialize();
      return stream; // Retourner le stream original si pas initialis√©
    }
    
    // D√©connecter l'ancienne source
    if (micSourceRef.current) {
      try {
        micSourceRef.current.disconnect();
      } catch (e) {
        // Ignore
      }
    }
    
    try {
      // Cr√©er la source √† partir du stream
      const source = ctx.createMediaStreamSource(stream);
      source.connect(micGainRef.current);
      micSourceRef.current = source;
      
      // Cr√©er un nouveau stream avec le gain appliqu√© pour WebRTC
      const destination = ctx.createMediaStreamDestination();
      micGainRef.current.connect(destination);
      
      console.log('üéß [AUDIO] Mic source connected to GainNode B');
      
      return destination.stream;
    } catch (err) {
      console.warn('üéß [AUDIO] Mic source connection error:', err);
      return stream;
    }
  }, [initialize]);

  /**
   * Connecte l'audio de la voix h√¥te pour les participants
   */
  const connectHostVoice = useCallback((audioElement: HTMLAudioElement) => {
    const ctx = audioContextRef.current;
    if (!ctx || !hostVoiceGainRef.current) {
      console.warn('üéß [AUDIO] Mixer not initialized for host voice');
      initialize();
      setTimeout(() => connectHostVoice(audioElement), 100);
      return;
    }
    
    if (connectedHostVoiceElement.current === audioElement && hostVoiceSourceRef.current) {
      return;
    }
    
    if (hostVoiceSourceRef.current) {
      try {
        hostVoiceSourceRef.current.disconnect();
      } catch (e) {
        // Ignore
      }
    }
    
    try {
      const source = ctx.createMediaElementSource(audioElement);
      source.connect(hostVoiceGainRef.current);
      
      hostVoiceSourceRef.current = source;
      connectedHostVoiceElement.current = audioElement;
      
      console.log('üéß [AUDIO] Host voice connected to GainNode D');
    } catch (err) {
      console.warn('üéß [AUDIO] Host voice connection error:', err);
    }
  }, [initialize]);

  /**
   * D√©finit le volume de la musique
   */
  const setMusicVolume = useCallback((volume: number) => {
    const clamped = Math.max(0, Math.min(1, volume));
    setState(prev => ({ ...prev, musicVolume: clamped }));
    
    if (musicGainRef.current) {
      musicGainRef.current.gain.setValueAtTime(clamped, audioContextRef.current?.currentTime || 0);
    }
  }, []);

  /**
   * D√©finit le volume du micro
   */
  const setMicVolume = useCallback((volume: number) => {
    const clamped = Math.max(0, Math.min(1, volume));
    setState(prev => ({ ...prev, micVolume: clamped }));
    
    if (micGainRef.current) {
      micGainRef.current.gain.setValueAtTime(clamped, audioContextRef.current?.currentTime || 0);
    }
  }, []);

  /**
   * D√©finit le volume de la tribu (participants)
   */
  const setTribeVolume = useCallback((volume: number) => {
    const clamped = Math.max(0, Math.min(1, volume));
    setState(prev => ({ ...prev, tribeVolume: clamped }));
    
    if (tribeGainRef.current) {
      tribeGainRef.current.gain.setValueAtTime(clamped, audioContextRef.current?.currentTime || 0);
    }
  }, []);

  /**
   * D√©finit le volume de la voix h√¥te (pour participants)
   */
  const setHostVoiceVolume = useCallback((volume: number) => {
    const clamped = Math.max(0, Math.min(1, volume));
    setState(prev => ({ ...prev, hostVoiceVolume: clamped }));
    
    if (hostVoiceGainRef.current) {
      hostVoiceGainRef.current.gain.setValueAtTime(clamped, audioContextRef.current?.currentTime || 0);
    }
    
    // Aussi mettre √† jour l'√©l√©ment audio directement pour le fallback
    const remoteAudio = document.getElementById('remote-voice-audio') as HTMLAudioElement;
    if (remoteAudio) {
      remoteAudio.volume = clamped;
    }
  }, []);

  /**
   * D√©connecte la source musique
   */
  const disconnectMusic = useCallback(() => {
    if (musicSourceRef.current) {
      try {
        musicSourceRef.current.disconnect();
      } catch (e) {
        // Ignore
      }
      musicSourceRef.current = null;
      connectedMusicElement.current = null;
    }
  }, []);

  /**
   * D√©connecte la source micro
   */
  const disconnectMic = useCallback(() => {
    if (micSourceRef.current) {
      try {
        micSourceRef.current.disconnect();
      } catch (e) {
        // Ignore
      }
      micSourceRef.current = null;
    }
  }, []);

  /**
   * Retourne l'AudioContext
   */
  const getContext = useCallback(() => audioContextRef.current, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      disconnectMusic();
      disconnectMic();
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close();
      }
    };
  }, [disconnectMusic, disconnectMic]);

  return {
    state,
    initialize,
    setMusicVolume,
    setMicVolume,
    setTribeVolume,
    setHostVoiceVolume,
    connectMusicSource,
    connectMicSource,
    connectHostVoice,
    disconnectMusic,
    disconnectMic,
    getContext,
  };
}

export default useAudioMixer;
